# ğŸ¤– Soulmate - çµé­‚ä¼´ä¾£èŠå¤©åŠ©æ‰‹

åŸºäº **Qwen3-1.7B** æ¨¡å‹ï¼Œä½¿ç”¨ **LoRA (Low-Rank Adaptation)** æŠ€æœ¯å¾®è°ƒçš„ä¸­æ–‡èŠå¤©åŠ©æ‰‹ã€‚è¯¥æ¨¡å‹ä¸“é—¨é’ˆå¯¹æƒ…æ„Ÿé™ªä¼´åœºæ™¯è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿä»¥è‡ªç„¶ã€å£è¯­åŒ–çš„æ–¹å¼è¿›è¡Œå¯¹è¯äº¤æµã€‚

---

## âœ¨ ç‰¹æ€§

- ğŸ¯ **è½»é‡çº§å¾®è°ƒ**ï¼šé‡‡ç”¨ LoRA æŠ€æœ¯ï¼Œä»…è®­ç»ƒå°‘é‡å‚æ•°ï¼ŒèŠ‚çœè®¡ç®—èµ„æº
- ğŸ’¬ **è‡ªç„¶å¯¹è¯**ï¼šç”Ÿæˆç®€çŸ­ã€æµç•…ã€å£è¯­åŒ–çš„å›å¤
- ğŸš€ **OpenAI å…¼å®¹ API**ï¼šæä¾›æ ‡å‡†çš„ `/v1/chat/completions` æ¥å£
- ğŸ **Apple Silicon æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒ MPS åŠ é€Ÿ (Mac Mç³»åˆ—èŠ¯ç‰‡)
- ğŸ“¦ **Response-Only è®­ç»ƒ**ï¼šä»…å¯¹åŠ©æ‰‹å›å¤éƒ¨åˆ†è®¡ç®—æŸå¤±ï¼Œè®­ç»ƒæ›´ç²¾å‡†

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
soulmate/
â”œâ”€â”€ finetune.py          # LoRA å¾®è°ƒè„šæœ¬
â”œâ”€â”€ server.py            # FastAPI æœåŠ¡ç«¯ (OpenAI å…¼å®¹ API)
â”œâ”€â”€ client.py            # å®¢æˆ·ç«¯æµ‹è¯•è„šæœ¬
â”œâ”€â”€ infer.py             # æœ¬åœ°æ¨ç†è„šæœ¬
â”œâ”€â”€ run.sh               # å¿«é€Ÿå¯åŠ¨æœåŠ¡è„šæœ¬
â”œâ”€â”€ requirements.txt     # Python ä¾èµ–
â”œâ”€â”€ datasets/            # è®­ç»ƒæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ train_0115_s.jsonl   # å°æ•°æ®é›† (1490 æ ·æœ¬)
â”‚   â””â”€â”€ train_0115_x.jsonl   # ä¸­ç­‰æ•°æ®é›† (4598 æ ·æœ¬)
â”œâ”€â”€ qwen_lora_adapter_0115_s/  # å°æ•°æ®é›†è®­ç»ƒçš„ LoRA é€‚é…å™¨
â””â”€â”€ qwen_lora_adapter_0115_x/  # ä¸­ç­‰æ•°æ®é›†è®­ç»ƒçš„ LoRA é€‚é…å™¨
```

---

## ğŸ› ï¸ å®‰è£…

### 1. å…‹éš†é¡¹ç›®å¹¶åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
git clone <your-repo-url>
cd soulmate

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**ä¾èµ–åˆ—è¡¨ï¼š**
- `transformers >= 4.57`
- `torch >= 2.9`
- `peft >= 0.18`
- `trl >= 0.26`
- `modelscope >= 1.33`
- `fastapi`
- `uvicorn`
- `openai`

---

## ğŸ“Š æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®ä½¿ç”¨ **JSONL** æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªå¯¹è¯æ ·æœ¬ï¼š

```json
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ´»æ³¼å¼€æœ—çš„ç”·ç”Ÿï¼Œå’Œæƒ³è¦è¿›ä¸€æ­¥è¿½æ±‚çš„å¥³ç”Ÿè¿›è¡Œå¯¹è¯..."},
    {"role": "user", "content": "æˆ‘ä»Šå¤©å·¥ä½œå¥½ç´¯ï¼Œåˆšä¸‹ç­"},
    {"role": "assistant", "content": "è¾›è‹¦å•¦ï¼ä¸‹ç­è·¯ä¸Šæ³¨æ„å®‰å…¨ï¼Œæƒ³åƒç‚¹ä»€ä¹ˆå¥½åƒçš„çŠ’åŠ³è‡ªå·±ï¼Ÿ"}
  ]
}
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨ API æœåŠ¡

```bash
# ä½¿ç”¨ run.sh å¿«é€Ÿå¯åŠ¨
bash run.sh

# æˆ–æ‰‹åŠ¨é…ç½®å¯åŠ¨
BASE_MODEL=Qwen/Qwen3-1.7B \
LORA_DIR=./qwen_lora_adapter_0115_x \
DEVICE=mps \
DTYPE=float16 \
SERVED_MODEL_NAME=soulmate \
uvicorn server:app --host 0.0.0.0 --port 8026
```

### 2. è°ƒç”¨ API

```python
from openai import OpenAI

client = OpenAI(base_url="http://127.0.0.1:8026/v1", api_key="dummy")

resp = client.chat.completions.create(
    model="soulmate",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè´´å¿ƒçš„ç”·ç”Ÿï¼Œèƒ½å¤ŸåŠæ—¶å›å¤å¥³ç”Ÿæ¶ˆæ¯"},
        {"role": "user", "content": "ä½ ä½å“ªï¼Ÿ"}
    ],
    temperature=0.7,
    top_p=0.7,
    max_tokens=1024,
)

print(resp.choices[0].message.content)
```

### 3. æœ¬åœ°æ¨ç† (æ— éœ€å¯åŠ¨æœåŠ¡)

```bash
python infer.py
```

---

## ğŸ”Œ API æ¥å£

### è·å–æ¨¡å‹åˆ—è¡¨

```bash
GET /v1/models
```

### èŠå¤©è¡¥å…¨

```bash
POST /v1/chat/completions
```

**è¯·æ±‚ä½“ï¼š**

```json
{
  "model": "soulmate",
  "messages": [
    {"role": "system", "content": "ç³»ç»Ÿæç¤ºè¯"},
    {"role": "user", "content": "ç”¨æˆ·æ¶ˆæ¯"}
  ],
  "temperature": 0.7,
  "top_p": 0.7,
  "max_tokens": 1024
}
```

**å“åº”ï¼š**

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "soulmate",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "åŠ©æ‰‹å›å¤å†…å®¹"
      },
      "finish_reason": "stop"
    }
  ]
}
```